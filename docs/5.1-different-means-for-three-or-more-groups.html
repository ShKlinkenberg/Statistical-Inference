<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.1 Different Means for Three or More Groups | Statitstical Inference</title>
  <meta name="description" content="5.1 Different Means for Three or More Groups | Statitstical Inference" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="5.1 Different Means for Three or More Groups | Statitstical Inference" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.1 Different Means for Three or More Groups | Statitstical Inference" />
  
  
  

<meta name="author" content="Wouter de Nooy" />
<meta name="author" content="et al." />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="5-anova.html"/>
<link rel="next" href="5.2-onewaySPSS.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="libs/vis-9.1.0/vis-network.min.css" rel="stylesheet" />
<script src="libs/vis-9.1.0/vis-network.min.js"></script>
<script src="libs/visNetwork-binding-2.1.2/visNetwork.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="styleX.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction and Reader’s Guide</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#intended-audience-and-setting"><i class="fa fa-check"></i>Intended Audience and Setting</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#interactive-content"><i class="fa fa-check"></i>Interactive Content</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#disclaimer"><i class="fa fa-check"></i>Disclaimer</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-samp-dist.html"><a href="1-samp-dist.html"><i class="fa fa-check"></i><b>1</b> Sampling Distribution: How Different Could My Sample Have Been?</a>
<ul>
<li class="chapter" data-level="" data-path="1-samp-dist.html"><a href="1-samp-dist.html#summary"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="1.1" data-path="1.1-statistical-inference-making-the-most-of-your-data.html"><a href="1.1-statistical-inference-making-the-most-of-your-data.html"><i class="fa fa-check"></i><b>1.1</b> Statistical Inference: Making the Most of Your Data</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-discreterandomvariable.html"><a href="1.2-discreterandomvariable.html"><i class="fa fa-check"></i><b>1.2</b> A Discrete Random Variable: How Many Yellow Candies in My Bag?</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="1.2-discreterandomvariable.html"><a href="1.2-discreterandomvariable.html#samplestatistic"><i class="fa fa-check"></i><b>1.2.1</b> Sample statistic</a></li>
<li class="chapter" data-level="1.2.2" data-path="1.2-discreterandomvariable.html"><a href="1.2-discreterandomvariable.html#sampling-distribution"><i class="fa fa-check"></i><b>1.2.2</b> Sampling distribution</a></li>
<li class="chapter" data-level="1.2.3" data-path="1.2-discreterandomvariable.html"><a href="1.2-discreterandomvariable.html#probdistribution"><i class="fa fa-check"></i><b>1.2.3</b> Probability and probability distribution</a></li>
<li class="chapter" data-level="1.2.4" data-path="1.2-discreterandomvariable.html"><a href="1.2-discreterandomvariable.html#expectedvalue"><i class="fa fa-check"></i><b>1.2.4</b> Expected value or expectation</a></li>
<li class="chapter" data-level="1.2.5" data-path="1.2-discreterandomvariable.html"><a href="1.2-discreterandomvariable.html#unbiased-est"><i class="fa fa-check"></i><b>1.2.5</b> Unbiased estimator</a></li>
<li class="chapter" data-level="1.2.6" data-path="1.2-discreterandomvariable.html"><a href="1.2-discreterandomvariable.html#representative"><i class="fa fa-check"></i><b>1.2.6</b> Representative sample</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1.3-cont-random-var.html"><a href="1.3-cont-random-var.html"><i class="fa fa-check"></i><b>1.3</b> A Continuous Random Variable: Overweight And Underweight.</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="1.3-cont-random-var.html"><a href="1.3-cont-random-var.html#continuous-variable"><i class="fa fa-check"></i><b>1.3.1</b> Continuous variable</a></li>
<li class="chapter" data-level="1.3.2" data-path="1.3-cont-random-var.html"><a href="1.3-cont-random-var.html#cont_sample_stat"><i class="fa fa-check"></i><b>1.3.2</b> Continuous sample statistic</a></li>
<li class="chapter" data-level="1.3.3" data-path="1.3-cont-random-var.html"><a href="1.3-cont-random-var.html#probability-density"><i class="fa fa-check"></i><b>1.3.3</b> Probability density</a></li>
<li class="chapter" data-level="1.3.4" data-path="1.3-cont-random-var.html"><a href="1.3-cont-random-var.html#probabilities-always-sum-to-1"><i class="fa fa-check"></i><b>1.3.4</b> Probabilities always sum to 1</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1.4-concluding-remarks.html"><a href="1.4-concluding-remarks.html"><i class="fa fa-check"></i><b>1.4</b> Concluding Remarks</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="1.4-concluding-remarks.html"><a href="1.4-concluding-remarks.html#sample-characteristics-as-observations"><i class="fa fa-check"></i><b>1.4.1</b> Sample characteristics as observations</a></li>
<li class="chapter" data-level="1.4.2" data-path="1.4-concluding-remarks.html"><a href="1.4-concluding-remarks.html#means-at-three-levels"><i class="fa fa-check"></i><b>1.4.2</b> Means at three levels</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="1.5-take-home-points.html"><a href="1.5-take-home-points.html"><i class="fa fa-check"></i><b>1.5</b> Take-Home Points</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-probmodels.html"><a href="2-probmodels.html"><i class="fa fa-check"></i><b>2</b> Probability Models: How Do I Get a Sampling Distribution?</a>
<ul>
<li class="chapter" data-level="" data-path="2-probmodels.html"><a href="2-probmodels.html#summary-1"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="2.1" data-path="2.1-exact-approaches-to-the-sampling-distribution.html"><a href="2.1-exact-approaches-to-the-sampling-distribution.html"><i class="fa fa-check"></i><b>2.1</b> Exact Approaches to the Sampling Distribution</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="2.1-exact-approaches-to-the-sampling-distribution.html"><a href="2.1-exact-approaches-to-the-sampling-distribution.html#exact-approaches-for-categorical-data"><i class="fa fa-check"></i><b>2.1.1</b> Exact approaches for categorical data</a></li>
<li class="chapter" data-level="2.1.2" data-path="2.1-exact-approaches-to-the-sampling-distribution.html"><a href="2.1-exact-approaches-to-the-sampling-distribution.html#computer-intensive"><i class="fa fa-check"></i><b>2.1.2</b> Computer-intensive</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2.2-SPSS-exact.html"><a href="2.2-SPSS-exact.html"><i class="fa fa-check"></i><b>2.2</b> Exact Approaches in SPSS</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2.2-SPSS-exact.html"><a href="2.2-SPSS-exact.html#introduction"><i class="fa fa-check"></i><b>2.2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2.2" data-path="2.2-SPSS-exact.html"><a href="2.2-SPSS-exact.html#instructions"><i class="fa fa-check"></i><b>2.2.2</b> Instructions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2.3-theoretical-approx.html"><a href="2.3-theoretical-approx.html"><i class="fa fa-check"></i><b>2.3</b> Theoretical Approximations of the Sampling Distribution</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="2.3-theoretical-approx.html"><a href="2.3-theoretical-approx.html#reasons-for-a-bell-shaped-probability-distribution"><i class="fa fa-check"></i><b>2.3.1</b> Reasons for a bell-shaped probability distribution</a></li>
<li class="chapter" data-level="2.3.2" data-path="2.3-theoretical-approx.html"><a href="2.3-theoretical-approx.html#cond-probdistr"><i class="fa fa-check"></i><b>2.3.2</b> Conditions for the use of theoretical probability distributions</a></li>
<li class="chapter" data-level="2.3.3" data-path="2.3-theoretical-approx.html"><a href="2.3-theoretical-approx.html#cond-check"><i class="fa fa-check"></i><b>2.3.3</b> Checking conditions</a></li>
<li class="chapter" data-level="2.3.4" data-path="2.3-theoretical-approx.html"><a href="2.3-theoretical-approx.html#complicatedsampling"><i class="fa fa-check"></i><b>2.3.4</b> More complicated sample statistics: differences</a></li>
<li class="chapter" data-level="2.3.5" data-path="2.3-theoretical-approx.html"><a href="2.3-theoretical-approx.html#independent-samples"><i class="fa fa-check"></i><b>2.3.5</b> Independent samples</a></li>
<li class="chapter" data-level="2.3.6" data-path="2.3-theoretical-approx.html"><a href="2.3-theoretical-approx.html#dependentsamples"><i class="fa fa-check"></i><b>2.3.6</b> Dependent samples</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2.4-spss-and-theoretical-approximation-of-the-sampling-distribution.html"><a href="2.4-spss-and-theoretical-approximation-of-the-sampling-distribution.html"><i class="fa fa-check"></i><b>2.4</b> SPSS and Theoretical Approximation of the Sampling Distribution</a></li>
<li class="chapter" data-level="2.5" data-path="2.5-boot-approx.html"><a href="2.5-boot-approx.html"><i class="fa fa-check"></i><b>2.5</b> The Bootstrap Approximation of the Sampling Distribution</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="2.5-boot-approx.html"><a href="2.5-boot-approx.html#sampling-with-and-without-replacement"><i class="fa fa-check"></i><b>2.5.1</b> Sampling with and without replacement</a></li>
<li class="chapter" data-level="2.5.2" data-path="2.5-boot-approx.html"><a href="2.5-boot-approx.html#limitations-to-bootstrapping"><i class="fa fa-check"></i><b>2.5.2</b> Limitations to bootstrapping</a></li>
<li class="chapter" data-level="2.5.3" data-path="2.5-boot-approx.html"><a href="2.5-boot-approx.html#any-sample-statistic-can-be-bootstrapped"><i class="fa fa-check"></i><b>2.5.3</b> Any sample statistic can be bootstrapped</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="2.6-boot-spss.html"><a href="2.6-boot-spss.html"><i class="fa fa-check"></i><b>2.6</b> Bootstrapping in SPSS</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="2.6-boot-spss.html"><a href="2.6-boot-spss.html#instructions-1"><i class="fa fa-check"></i><b>2.6.1</b> Instructions</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="2.7-when-do-we-use-which-approach-to-the-sampling-distribution.html"><a href="2.7-when-do-we-use-which-approach-to-the-sampling-distribution.html"><i class="fa fa-check"></i><b>2.7</b> When Do We Use Which Approach to the Sampling Distribution?</a></li>
<li class="chapter" data-level="2.8" data-path="2.8-take-home-points-1.html"><a href="2.8-take-home-points-1.html"><i class="fa fa-check"></i><b>2.8</b> Take-Home Points</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-param-estim.html"><a href="3-param-estim.html"><i class="fa fa-check"></i><b>3</b> Estimating a Parameter: Which Population Values Are Plausible?</a>
<ul>
<li class="chapter" data-level="" data-path="3-param-estim.html"><a href="3-param-estim.html#summary-2"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="3.1" data-path="3.1-point-estimate.html"><a href="3.1-point-estimate.html"><i class="fa fa-check"></i><b>3.1</b> Point Estimate</a></li>
<li class="chapter" data-level="3.2" data-path="3.2-interval-estimate-for-the-sample-statistic.html"><a href="3.2-interval-estimate-for-the-sample-statistic.html"><i class="fa fa-check"></i><b>3.2</b> Interval Estimate for the Sample Statistic</a></li>
<li class="chapter" data-level="3.3" data-path="3.3-precisionsesamplesize.html"><a href="3.3-precisionsesamplesize.html"><i class="fa fa-check"></i><b>3.3</b> Precision, Standard Error, and Sample Size</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3.3-precisionsesamplesize.html"><a href="3.3-precisionsesamplesize.html#sample-sizes"><i class="fa fa-check"></i><b>3.3.1</b> Sample sizes</a></li>
<li class="chapter" data-level="3.3.2" data-path="3.3-precisionsesamplesize.html"><a href="3.3-precisionsesamplesize.html#standard-error"><i class="fa fa-check"></i><b>3.3.2</b> Standard error</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3.4-crit-values.html"><a href="3.4-crit-values.html"><i class="fa fa-check"></i><b>3.4</b> Critical Values</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="3.4-crit-values.html"><a href="3.4-crit-values.html#standardization-and-z-scores"><i class="fa fa-check"></i><b>3.4.1</b> Standardization and <em>z</em> scores</a></li>
<li class="chapter" data-level="3.4.2" data-path="3.4-crit-values.html"><a href="3.4-crit-values.html#int-est-sample-mean"><i class="fa fa-check"></i><b>3.4.2</b> Interval estimates from critical values and standard errors</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3.5-ci-parameter.html"><a href="3.5-ci-parameter.html"><i class="fa fa-check"></i><b>3.5</b> Confidence Interval for a Parameter</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="3.5-ci-parameter.html"><a href="3.5-ci-parameter.html#fixed-pop-values"><i class="fa fa-check"></i><b>3.5.1</b> Reverse reasoning from one sample mean</a></li>
<li class="chapter" data-level="3.5.2" data-path="3.5-ci-parameter.html"><a href="3.5-ci-parameter.html#conf-interval"><i class="fa fa-check"></i><b>3.5.2</b> One confidence interval does not say anything</a></li>
<li class="chapter" data-level="3.5.3" data-path="3.5-ci-parameter.html"><a href="3.5-ci-parameter.html#bootstrap-confidenceinterval"><i class="fa fa-check"></i><b>3.5.3</b> Confidence intervals with bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3.6-SPSS-CI.html"><a href="3.6-SPSS-CI.html"><i class="fa fa-check"></i><b>3.6</b> Confidence Intervals in SPSS</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="3.6-SPSS-CI.html"><a href="3.6-SPSS-CI.html#instruction"><i class="fa fa-check"></i><b>3.6.1</b> Instruction</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="3.7-take-home-points-2.html"><a href="3.7-take-home-points-2.html"><i class="fa fa-check"></i><b>3.7</b> Take-Home Points</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-hypothesis.html"><a href="4-hypothesis.html"><i class="fa fa-check"></i><b>4</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="" data-path="4-hypothesis.html"><a href="4-hypothesis.html#summary-3"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="4.1" data-path="4.1-binarydecision.html"><a href="4.1-binarydecision.html"><i class="fa fa-check"></i><b>4.1</b> Hypothesis</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="4.1-binarydecision.html"><a href="4.1-binarydecision.html#null-hypothesis"><i class="fa fa-check"></i><b>4.1.1</b> Null hypothesis</a></li>
<li class="chapter" data-level="4.1.2" data-path="4.1-binarydecision.html"><a href="4.1-binarydecision.html#alternative-hypothesis"><i class="fa fa-check"></i><b>4.1.2</b> Alternative hypothesis</a></li>
<li class="chapter" data-level="4.1.3" data-path="4.1-binarydecision.html"><a href="4.1-binarydecision.html#testing-hypothesis"><i class="fa fa-check"></i><b>4.1.3</b> Testing hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html"><i class="fa fa-check"></i><b>4.2</b> Null Hypothesis Significance Testing</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#alpha"><i class="fa fa-check"></i><b>4.2.1</b> Alpha</a></li>
<li class="chapter" data-level="4.2.2" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#alpha-1"><i class="fa fa-check"></i><b>4.2.2</b> 1 - Alpha</a></li>
<li class="chapter" data-level="4.2.3" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#power"><i class="fa fa-check"></i><b>4.2.3</b> Power</a></li>
<li class="chapter" data-level="4.2.4" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#beta"><i class="fa fa-check"></i><b>4.2.4</b> Beta</a></li>
<li class="chapter" data-level="4.2.5" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#test-statistic"><i class="fa fa-check"></i><b>4.2.5</b> Test statistic</a></li>
<li class="chapter" data-level="4.2.6" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#pvalue"><i class="fa fa-check"></i><b>4.2.6</b> P-value</a></li>
<li class="chapter" data-level="4.2.7" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#true-effect-size"><i class="fa fa-check"></i><b>4.2.7</b> True effect size</a></li>
<li class="chapter" data-level="4.2.8" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#observed-effect-size"><i class="fa fa-check"></i><b>4.2.8</b> Observed effect size</a></li>
<li class="chapter" data-level="4.2.9" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#post-hoc-power"><i class="fa fa-check"></i><b>4.2.9</b> Post hoc power</a></li>
<li class="chapter" data-level="4.2.10" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#meta-analysis"><i class="fa fa-check"></i><b>4.2.10</b> Meta analysis</a></li>
<li class="chapter" data-level="4.2.11" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#sample-size"><i class="fa fa-check"></i><b>4.2.11</b> Sample size</a></li>
<li class="chapter" data-level="4.2.12" data-path="4.2-null-hypothesis-significance-testing.html"><a href="4.2-null-hypothesis-significance-testing.html#one-twosidedtests"><i class="fa fa-check"></i><b>4.2.12</b> One-Sided and Two-Sided Tests</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4.3-reporting.html"><a href="4.3-reporting.html"><i class="fa fa-check"></i><b>4.3</b> Reporting test results</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="4.3-reporting.html"><a href="4.3-reporting.html#reporting-to-fellow-scientists"><i class="fa fa-check"></i><b>4.3.1</b> Reporting to fellow scientists</a></li>
<li class="chapter" data-level="4.3.2" data-path="4.3-reporting.html"><a href="4.3-reporting.html#reporting-to-the-general-reader"><i class="fa fa-check"></i><b>4.3.2</b> Reporting to the general reader</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4.4-test-selection.html"><a href="4.4-test-selection.html"><i class="fa fa-check"></i><b>4.4</b> Statistical test selection</a></li>
<li class="chapter" data-level="4.5" data-path="4.5-null-ci.html"><a href="4.5-null-ci.html"><i class="fa fa-check"></i><b>4.5</b> Confidence Intervals to test hypotheses</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="4.5-null-ci.html"><a href="4.5-null-ci.html#estimation-in-addidion-to-nhst"><i class="fa fa-check"></i><b>4.5.1</b> Estimation in addidion to NHST</a></li>
<li class="chapter" data-level="4.5.2" data-path="4.5-null-ci.html"><a href="4.5-null-ci.html#bootstrapped-confidence-intervals"><i class="fa fa-check"></i><b>4.5.2</b> Bootstrapped confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4.6-bayesian-hypothesis-testing.html"><a href="4.6-bayesian-hypothesis-testing.html"><i class="fa fa-check"></i><b>4.6</b> Bayesian hypothesis testing</a></li>
<li class="chapter" data-level="4.7" data-path="4.7-critical-discussion.html"><a href="4.7-critical-discussion.html"><i class="fa fa-check"></i><b>4.7</b> Critical Discussion</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="4.7-critical-discussion.html"><a href="4.7-critical-discussion.html#criticismsNHST"><i class="fa fa-check"></i><b>4.7.1</b> Criticisms of Null Hypothesis Significance Testing</a></li>
<li class="chapter" data-level="4.7.2" data-path="4.7-critical-discussion.html"><a href="4.7-critical-discussion.html#statistical-significance-is-not-a-measure-of-effect-size"><i class="fa fa-check"></i><b>4.7.2</b> Statistical significance is not a measure of effect size</a></li>
<li class="chapter" data-level="4.7.3" data-path="4.7-critical-discussion.html"><a href="4.7-critical-discussion.html#cap-chance"><i class="fa fa-check"></i><b>4.7.3</b> Capitalization on Chance</a></li>
<li class="chapter" data-level="4.7.4" data-path="4.7-critical-discussion.html"><a href="4.7-critical-discussion.html#no-random-sample"><i class="fa fa-check"></i><b>4.7.4</b> What If I Do Not Have a Random Sample?</a></li>
<li class="chapter" data-level="4.7.5" data-path="4.7-critical-discussion.html"><a href="4.7-critical-discussion.html#specifying-hypotheses-afterwards"><i class="fa fa-check"></i><b>4.7.5</b> Specifying hypotheses afterwards</a></li>
<li class="chapter" data-level="4.7.6" data-path="4.7-critical-discussion.html"><a href="4.7-critical-discussion.html#replication"><i class="fa fa-check"></i><b>4.7.6</b> Replication</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="4.8-take-home-points-3.html"><a href="4.8-take-home-points-3.html"><i class="fa fa-check"></i><b>4.8</b> Take home points</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-anova.html"><a href="5-anova.html"><i class="fa fa-check"></i><b>5</b> Moderation with Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="" data-path="5-anova.html"><a href="5-anova.html#summary-4"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="5.1" data-path="5.1-different-means-for-three-or-more-groups.html"><a href="5.1-different-means-for-three-or-more-groups.html"><i class="fa fa-check"></i><b>5.1</b> Different Means for Three or More Groups</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="5.1-different-means-for-three-or-more-groups.html"><a href="5.1-different-means-for-three-or-more-groups.html#anova-meandiffs"><i class="fa fa-check"></i><b>5.1.1</b> Mean differences as effects</a></li>
<li class="chapter" data-level="5.1.2" data-path="5.1-different-means-for-three-or-more-groups.html"><a href="5.1-different-means-for-three-or-more-groups.html#between-variance"><i class="fa fa-check"></i><b>5.1.2</b> Between-groups variance and within-groups variance</a></li>
<li class="chapter" data-level="5.1.3" data-path="5.1-different-means-for-three-or-more-groups.html"><a href="5.1-different-means-for-three-or-more-groups.html#anova-model"><i class="fa fa-check"></i><b>5.1.3</b> <em>F</em> test on the model</a></li>
<li class="chapter" data-level="5.1.4" data-path="5.1-different-means-for-three-or-more-groups.html"><a href="5.1-different-means-for-three-or-more-groups.html#anova-assumpt"><i class="fa fa-check"></i><b>5.1.4</b> Assumptions for the <em>F</em> test in analysis of variance</a></li>
<li class="chapter" data-level="5.1.5" data-path="5.1-different-means-for-three-or-more-groups.html"><a href="5.1-different-means-for-three-or-more-groups.html#which-groups-have-different-average-scores"><i class="fa fa-check"></i><b>5.1.5</b> Which groups have different average scores?</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5.2-onewaySPSS.html"><a href="5.2-onewaySPSS.html"><i class="fa fa-check"></i><b>5.2</b> One-Way Analysis of Variance in SPSS</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="5.2-onewaySPSS.html"><a href="5.2-onewaySPSS.html#instructions-2"><i class="fa fa-check"></i><b>5.2.1</b> Instructions</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5.3-different-means-for-two-factors.html"><a href="5.3-different-means-for-two-factors.html"><i class="fa fa-check"></i><b>5.3</b> Different Means for Two Factors</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="5.3-different-means-for-two-factors.html"><a href="5.3-different-means-for-two-factors.html#anova2way"><i class="fa fa-check"></i><b>5.3.1</b> Two-way analysis of variance</a></li>
<li class="chapter" data-level="5.3.2" data-path="5.3-different-means-for-two-factors.html"><a href="5.3-different-means-for-two-factors.html#balanced"><i class="fa fa-check"></i><b>5.3.2</b> Balanced design</a></li>
<li class="chapter" data-level="5.3.3" data-path="5.3-different-means-for-two-factors.html"><a href="5.3-different-means-for-two-factors.html#maineffects"><i class="fa fa-check"></i><b>5.3.3</b> Main effects in two-way analysis of variance</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="5.4-moderationanova.html"><a href="5.4-moderationanova.html"><i class="fa fa-check"></i><b>5.4</b> Moderation: Group-Level Differences that Depend on Context</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="5.4-moderationanova.html"><a href="5.4-moderationanova.html#types-of-moderation"><i class="fa fa-check"></i><b>5.4.1</b> Types of moderation</a></li>
<li class="chapter" data-level="5.4.2" data-path="5.4-moderationanova.html"><a href="5.4-moderationanova.html#testing-main-and-interaction-effects"><i class="fa fa-check"></i><b>5.4.2</b> Testing main and interaction effects</a></li>
<li class="chapter" data-level="5.4.3" data-path="5.4-moderationanova.html"><a href="5.4-moderationanova.html#assumptions-for-two-way-analysis-of-variance"><i class="fa fa-check"></i><b>5.4.3</b> Assumptions for two-way analysis of variance</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="5.5-reporting-two-way-analysis-of-variance.html"><a href="5.5-reporting-two-way-analysis-of-variance.html"><i class="fa fa-check"></i><b>5.5</b> Reporting Two-Way Analysis of Variance</a></li>
<li class="chapter" data-level="5.6" data-path="5.6-twowaySPSS.html"><a href="5.6-twowaySPSS.html"><i class="fa fa-check"></i><b>5.6</b> Two-Way Analysis of Variance in SPSS</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="5.6-twowaySPSS.html"><a href="5.6-twowaySPSS.html#instructions-3"><i class="fa fa-check"></i><b>5.6.1</b> Instructions</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="5.7-take-home-points-4.html"><a href="5.7-take-home-points-4.html"><i class="fa fa-check"></i><b>5.7</b> Take-Home Points</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-moderationcat.html"><a href="6-moderationcat.html"><i class="fa fa-check"></i><b>6</b> Regression Analysis And A Categorical Moderator</a>
<ul>
<li class="chapter" data-level="" data-path="6-moderationcat.html"><a href="6-moderationcat.html#summary-5"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="6.1" data-path="6.1-regression-equation.html"><a href="6.1-regression-equation.html"><i class="fa fa-check"></i><b>6.1</b> The Regression Equation</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="6.1-regression-equation.html"><a href="6.1-regression-equation.html#a-numerical-predictor"><i class="fa fa-check"></i><b>6.1.1</b> A numerical predictor</a></li>
<li class="chapter" data-level="6.1.2" data-path="6.1-regression-equation.html"><a href="6.1-regression-equation.html#dichpredictor"><i class="fa fa-check"></i><b>6.1.2</b> Dichotomous predictors</a></li>
<li class="chapter" data-level="6.1.3" data-path="6.1-regression-equation.html"><a href="6.1-regression-equation.html#categorical-predictor"><i class="fa fa-check"></i><b>6.1.3</b> A categorical independent variable and dummy variables</a></li>
<li class="chapter" data-level="6.1.4" data-path="6.1-regression-equation.html"><a href="6.1-regression-equation.html#regr-inference"><i class="fa fa-check"></i><b>6.1.4</b> Sampling distributions and assumptions</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6.2-SPSS-regression.html"><a href="6.2-SPSS-regression.html"><i class="fa fa-check"></i><b>6.2</b> Regression Analysis in SPSS</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="6.2-SPSS-regression.html"><a href="6.2-SPSS-regression.html#instructions-4"><i class="fa fa-check"></i><b>6.2.1</b> Instructions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6.3-categoricalmoderator.html"><a href="6.3-categoricalmoderator.html"><i class="fa fa-check"></i><b>6.3</b> Different Lines for Different Groups</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="6.3-categoricalmoderator.html"><a href="6.3-categoricalmoderator.html#a-dichotomous-moderator-and-numerical-predictor"><i class="fa fa-check"></i><b>6.3.1</b> A dichotomous moderator and numerical predictor</a></li>
<li class="chapter" data-level="6.3.2" data-path="6.3-categoricalmoderator.html"><a href="6.3-categoricalmoderator.html#interaction-variable"><i class="fa fa-check"></i><b>6.3.2</b> Interaction variable</a></li>
<li class="chapter" data-level="6.3.3" data-path="6.3-categoricalmoderator.html"><a href="6.3-categoricalmoderator.html#conditional-effects"><i class="fa fa-check"></i><b>6.3.3</b> Conditional effects, not main effects</a></li>
<li class="chapter" data-level="6.3.4" data-path="6.3-categoricalmoderator.html"><a href="6.3-categoricalmoderator.html#interactioninterpretation"><i class="fa fa-check"></i><b>6.3.4</b> Interpretation and statistical inference</a></li>
<li class="chapter" data-level="6.3.5" data-path="6.3-categoricalmoderator.html"><a href="6.3-categoricalmoderator.html#a-categorical-moderator"><i class="fa fa-check"></i><b>6.3.5</b> A categorical moderator</a></li>
<li class="chapter" data-level="6.3.6" data-path="6.3-categoricalmoderator.html"><a href="6.3-categoricalmoderator.html#commonsupportdichotomous"><i class="fa fa-check"></i><b>6.3.6</b> Common support</a></li>
<li class="chapter" data-level="6.3.7" data-path="6.3-categoricalmoderator.html"><a href="6.3-categoricalmoderator.html#visualizing-moderation-and-covariates"><i class="fa fa-check"></i><b>6.3.7</b> Visualizing moderation and covariates</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6.4-catmodSPSS.html"><a href="6.4-catmodSPSS.html"><i class="fa fa-check"></i><b>6.4</b> A Dichotomous or Categorical Moderator in SPSS</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="6.4-catmodSPSS.html"><a href="6.4-catmodSPSS.html#instructions-5"><i class="fa fa-check"></i><b>6.4.1</b> Instructions</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6.5-take-home-points-5.html"><a href="6.5-take-home-points-5.html"><i class="fa fa-check"></i><b>6.5</b> Take-Home Points</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-moderationcont.html"><a href="7-moderationcont.html"><i class="fa fa-check"></i><b>7</b> Regression Analysis With A Numerical Moderator</a>
<ul>
<li class="chapter" data-level="" data-path="7-moderationcont.html"><a href="7-moderationcont.html#summary-6"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="7.1" data-path="7.1-cont-moderator-regression.html"><a href="7.1-cont-moderator-regression.html"><i class="fa fa-check"></i><b>7.1</b> A Numerical Moderator</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="7.1-cont-moderator-regression.html"><a href="7.1-cont-moderator-regression.html#interpret-cont-interaction"><i class="fa fa-check"></i><b>7.1.1</b> Interaction variable</a></li>
<li class="chapter" data-level="7.1.2" data-path="7.1-cont-moderator-regression.html"><a href="7.1-cont-moderator-regression.html#conditional-effect-cont"><i class="fa fa-check"></i><b>7.1.2</b> Conditional effect</a></li>
<li class="chapter" data-level="7.1.3" data-path="7.1-cont-moderator-regression.html"><a href="7.1-cont-moderator-regression.html#mean-centering"><i class="fa fa-check"></i><b>7.1.3</b> Mean-centering</a></li>
<li class="chapter" data-level="7.1.4" data-path="7.1-cont-moderator-regression.html"><a href="7.1-cont-moderator-regression.html#symmetry-of-predictor-and-moderator"><i class="fa fa-check"></i><b>7.1.4</b> Symmetry of predictor and moderator</a></li>
<li class="chapter" data-level="7.1.5" data-path="7.1-cont-moderator-regression.html"><a href="7.1-cont-moderator-regression.html#visualization-of-the-interaction-effect"><i class="fa fa-check"></i><b>7.1.5</b> Visualization of the interaction effect</a></li>
<li class="chapter" data-level="7.1.6" data-path="7.1-cont-moderator-regression.html"><a href="7.1-cont-moderator-regression.html#statistical-inference-on-conditional-effects"><i class="fa fa-check"></i><b>7.1.6</b> Statistical inference on conditional effects</a></li>
<li class="chapter" data-level="7.1.7" data-path="7.1-cont-moderator-regression.html"><a href="7.1-cont-moderator-regression.html#common-support"><i class="fa fa-check"></i><b>7.1.7</b> Common support</a></li>
<li class="chapter" data-level="7.1.8" data-path="7.1-cont-moderator-regression.html"><a href="7.1-cont-moderator-regression.html#assumptions"><i class="fa fa-check"></i><b>7.1.8</b> Assumptions</a></li>
<li class="chapter" data-level="7.1.9" data-path="7.1-cont-moderator-regression.html"><a href="7.1-cont-moderator-regression.html#higher-order-interaction-effects"><i class="fa fa-check"></i><b>7.1.9</b> Higher-order interaction effects</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7.2-reportmoderation.html"><a href="7.2-reportmoderation.html"><i class="fa fa-check"></i><b>7.2</b> Reporting Regression Results</a></li>
<li class="chapter" data-level="7.3" data-path="7.3-RegressionContModSPSS.html"><a href="7.3-RegressionContModSPSS.html"><i class="fa fa-check"></i><b>7.3</b> A Numerical Moderator in SPSS</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="7.3-RegressionContModSPSS.html"><a href="7.3-RegressionContModSPSS.html#instructions-6"><i class="fa fa-check"></i><b>7.3.1</b> Instructions</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7.4-take-home-points-6.html"><a href="7.4-take-home-points-6.html"><i class="fa fa-check"></i><b>7.4</b> Take-Home Points</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-confounder.html"><a href="8-confounder.html"><i class="fa fa-check"></i><b>8</b> Regression Analysis And Confounders</a>
<ul>
<li class="chapter" data-level="" data-path="8-confounder.html"><a href="8-confounder.html#summary-7"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="8.1" data-path="8.1-controlling.html"><a href="8.1-controlling.html"><i class="fa fa-check"></i><b>8.1</b> Controlling for Effects of Other Predictors</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="8.1-controlling.html"><a href="8.1-controlling.html#partialeffect"><i class="fa fa-check"></i><b>8.1.1</b> Partial effect</a></li>
<li class="chapter" data-level="8.1.2" data-path="8.1-controlling.html"><a href="8.1-controlling.html#confounding-variables"><i class="fa fa-check"></i><b>8.1.2</b> Confounding variables</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8.2-indirectcorrelation.html"><a href="8.2-indirectcorrelation.html"><i class="fa fa-check"></i><b>8.2</b> Indirect Correlation</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="8.2-indirectcorrelation.html"><a href="8.2-indirectcorrelation.html#indirect-correlation-and-size-of-confounding"><i class="fa fa-check"></i><b>8.2.1</b> Indirect correlation and size of confounding</a></li>
<li class="chapter" data-level="8.2.2" data-path="8.2-indirectcorrelation.html"><a href="8.2-indirectcorrelation.html#confounders-are-not-included-in-the-regression-model"><i class="fa fa-check"></i><b>8.2.2</b> Confounders are not included in the regression model</a></li>
<li class="chapter" data-level="8.2.3" data-path="8.2-indirectcorrelation.html"><a href="8.2-indirectcorrelation.html#randomization"><i class="fa fa-check"></i><b>8.2.3</b> Randomization for avoiding confounders</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8.3-confounders.html"><a href="8.3-confounders.html"><i class="fa fa-check"></i><b>8.3</b> Two Types of Confounders</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="8.3-confounders.html"><a href="8.3-confounders.html#suppression"><i class="fa fa-check"></i><b>8.3.1</b> Suppression</a></li>
<li class="chapter" data-level="8.3.2" data-path="8.3-confounders.html"><a href="8.3-confounders.html#spuriousness"><i class="fa fa-check"></i><b>8.3.2</b> Reinforcement and spuriousness</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8.4-compmodelSSPSS.html"><a href="8.4-compmodelSSPSS.html"><i class="fa fa-check"></i><b>8.4</b> Comparing Regression Models in SPSS</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="8.4-compmodelSSPSS.html"><a href="8.4-compmodelSSPSS.html#instructions-7"><i class="fa fa-check"></i><b>8.4.1</b> Instructions</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="8.5-take-home-points-7.html"><a href="8.5-take-home-points-7.html"><i class="fa fa-check"></i><b>8.5</b> Take-Home Points</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-mediation.html"><a href="9-mediation.html"><i class="fa fa-check"></i><b>9</b> Mediation with Regression Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="9-mediation.html"><a href="9-mediation.html#summary-8"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="9.1" data-path="9.1-mediation-as-causal-process.html"><a href="9.1-mediation-as-causal-process.html"><i class="fa fa-check"></i><b>9.1</b> Mediation as Causal Process</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="9.1-mediation-as-causal-process.html"><a href="9.1-mediation-as-causal-process.html#causalcriteria"><i class="fa fa-check"></i><b>9.1.1</b> Criteria for a causal relation</a></li>
<li class="chapter" data-level="9.1.2" data-path="9.1-mediation-as-causal-process.html"><a href="9.1-mediation-as-causal-process.html#indirecteffect"><i class="fa fa-check"></i><b>9.1.2</b> Mediation as indirect effect</a></li>
<li class="chapter" data-level="9.1.3" data-path="9.1-mediation-as-causal-process.html"><a href="9.1-mediation-as-causal-process.html#causal-process"><i class="fa fa-check"></i><b>9.1.3</b> Causal process</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9.2-path-model-with-regression-analysis.html"><a href="9.2-path-model-with-regression-analysis.html"><i class="fa fa-check"></i><b>9.2</b> Path Model with Regression Analysis</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="9.2-path-model-with-regression-analysis.html"><a href="9.2-path-model-with-regression-analysis.html#requirements"><i class="fa fa-check"></i><b>9.2.1</b> Requirements</a></li>
<li class="chapter" data-level="9.2.2" data-path="9.2-path-model-with-regression-analysis.html"><a href="9.2-path-model-with-regression-analysis.html#size-indirect-effects"><i class="fa fa-check"></i><b>9.2.2</b> Size of indirect effects</a></li>
<li class="chapter" data-level="9.2.3" data-path="9.2-path-model-with-regression-analysis.html"><a href="9.2-path-model-with-regression-analysis.html#direction-of-indirect-effects"><i class="fa fa-check"></i><b>9.2.3</b> Direction of indirect effects</a></li>
<li class="chapter" data-level="9.2.4" data-path="9.2-path-model-with-regression-analysis.html"><a href="9.2-path-model-with-regression-analysis.html#partialserialmediation"><i class="fa fa-check"></i><b>9.2.4</b> Parallel and serial mediation</a></li>
<li class="chapter" data-level="9.2.5" data-path="9.2-path-model-with-regression-analysis.html"><a href="9.2-path-model-with-regression-analysis.html#partialfullmediation"><i class="fa fa-check"></i><b>9.2.5</b> Partial and full mediation</a></li>
<li class="chapter" data-level="9.2.6" data-path="9.2-path-model-with-regression-analysis.html"><a href="9.2-path-model-with-regression-analysis.html#significance-of-indirect-effects"><i class="fa fa-check"></i><b>9.2.6</b> Significance of indirect effects</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9.3-mediationcovariate.html"><a href="9.3-mediationcovariate.html"><i class="fa fa-check"></i><b>9.3</b> Controlling for Covariates</a></li>
<li class="chapter" data-level="9.4" data-path="9.4-reporting-mediation-results.html"><a href="9.4-reporting-mediation-results.html"><i class="fa fa-check"></i><b>9.4</b> Reporting Mediation Results</a></li>
<li class="chapter" data-level="9.5" data-path="9.5-SPSSPROCESS.html"><a href="9.5-SPSSPROCESS.html"><i class="fa fa-check"></i><b>9.5</b> Mediation with SPSS and PROCESS</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="9.5-SPSSPROCESS.html"><a href="9.5-SPSSPROCESS.html#instructions-8"><i class="fa fa-check"></i><b>9.5.1</b> Instructions</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="9.6-criticisms-of-mediation.html"><a href="9.6-criticisms-of-mediation.html"><i class="fa fa-check"></i><b>9.6</b> Criticisms of Mediation</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="9.6-criticisms-of-mediation.html"><a href="9.6-criticisms-of-mediation.html#causal-order-assumed"><i class="fa fa-check"></i><b>9.6.1</b> Causal order assumed</a></li>
<li class="chapter" data-level="9.6.2" data-path="9.6-criticisms-of-mediation.html"><a href="9.6-criticisms-of-mediation.html#time-order"><i class="fa fa-check"></i><b>9.6.2</b> Time order</a></li>
<li class="chapter" data-level="9.6.3" data-path="9.6-criticisms-of-mediation.html"><a href="9.6-criticisms-of-mediation.html#causality-or-underlying-construct"><i class="fa fa-check"></i><b>9.6.3</b> Causality or underlying construct?</a></li>
<li class="chapter" data-level="9.6.4" data-path="9.6-criticisms-of-mediation.html"><a href="9.6-criticisms-of-mediation.html#every-effect-in-a-path-model-can-be-confounded"><i class="fa fa-check"></i><b>9.6.4</b> Every effect in a path model can be confounded</a></li>
<li class="chapter" data-level="9.6.5" data-path="9.6-criticisms-of-mediation.html"><a href="9.6-criticisms-of-mediation.html#recommendations"><i class="fa fa-check"></i><b>9.6.5</b> Recommendations</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="9.7-combining-mediation-and-moderation.html"><a href="9.7-combining-mediation-and-moderation.html"><i class="fa fa-check"></i><b>9.7</b> Combining Mediation and Moderation</a></li>
<li class="chapter" data-level="9.8" data-path="9.8-take-home-points-8.html"><a href="9.8-take-home-points-8.html"><i class="fa fa-check"></i><b>9.8</b> Take-Home Points</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="flow-chart-statistical-test-selection.html"><a href="flow-chart-statistical-test-selection.html"><i class="fa fa-check"></i>Flow chart statistical test selection</a></li>
<li class="chapter" data-level="" data-path="all-spss-tutorial-videos-list.html"><a href="all-spss-tutorial-videos-list.html"><i class="fa fa-check"></i>All SPSS Tutorial Videos List</a></li>
<li class="chapter" data-level="" data-path="formulating-statistical-hypotheses.html"><a href="formulating-statistical-hypotheses.html"><i class="fa fa-check"></i>Formulating Statistical Hypotheses</a></li>
<li class="chapter" data-level="" data-path="proportions-shares.html"><a href="proportions-shares.html"><i class="fa fa-check"></i>Proportions: shares</a>
<ul>
<li class="chapter" data-level="" data-path="proportions-shares.html"><a href="proportions-shares.html#testing-proportions-in-spss"><i class="fa fa-check"></i>Testing proportions in SPSS</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="mean-and-median-level.html"><a href="mean-and-median-level.html"><i class="fa fa-check"></i>Mean and median: level</a>
<ul>
<li class="chapter" data-level="" data-path="mean-and-median-level.html"><a href="mean-and-median-level.html#testing-one-mean-or-median-in-spss"><i class="fa fa-check"></i>Testing one mean or median in SPSS</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="variance-disagreement.html"><a href="variance-disagreement.html"><i class="fa fa-check"></i>Variance: (dis)agreement</a>
<ul>
<li class="chapter" data-level="" data-path="variance-disagreement.html"><a href="variance-disagreement.html#testing-two-variances-in-spss"><i class="fa fa-check"></i>Testing two variances in SPSS</a></li>
<li class="chapter" data-level="" data-path="variance-disagreement.html"><a href="variance-disagreement.html#answers"><i class="fa fa-check"></i>Answers</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="association-relations-between-characteristics.html"><a href="association-relations-between-characteristics.html"><i class="fa fa-check"></i>Association: relations between characteristics</a>
<ul>
<li class="chapter" data-level="" data-path="association-relations-between-characteristics.html"><a href="association-relations-between-characteristics.html#score-level-differences"><i class="fa fa-check"></i>Score level differences</a></li>
<li class="chapter" data-level="" data-path="association-relations-between-characteristics.html"><a href="association-relations-between-characteristics.html#comparing-means-in-spss"><i class="fa fa-check"></i>Comparing means in SPSS</a></li>
<li class="chapter" data-level="" data-path="association-relations-between-characteristics.html"><a href="association-relations-between-characteristics.html#answers-1"><i class="fa fa-check"></i>Answers</a></li>
<li class="chapter" data-level="" data-path="association-relations-between-characteristics.html"><a href="association-relations-between-characteristics.html#combinations-of-scores"><i class="fa fa-check"></i>Combinations of scores</a></li>
<li class="chapter" data-level="" data-path="association-relations-between-characteristics.html"><a href="association-relations-between-characteristics.html#testing-associations-in-spss"><i class="fa fa-check"></i>Testing associations in SPSS</a></li>
<li class="chapter" data-level="" data-path="association-relations-between-characteristics.html"><a href="association-relations-between-characteristics.html#answers-2"><i class="fa fa-check"></i>Answers</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="9.9-CohenCalculations.html"><a href="9.9-CohenCalculations.html"><i class="fa fa-check"></i><b>9.9</b> Cohen’s <em>d</em> calculatons</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="9.9-CohenCalculations.html"><a href="9.9-CohenCalculations.html#obtaining-cohens-d-with-spss"><i class="fa fa-check"></i><b>9.9.1</b> Obtaining Cohen’s <em>d</em> with SPSS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statitstical Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="different-means-for-three-or-more-groups" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Different Means for Three or More Groups<a href="5.1-different-means-for-three-or-more-groups.html#different-means-for-three-or-more-groups" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Celebrity endorsement theory states that celebrities who publicly state that they favour a product, candidate, or cause, help to persuade consumers to adopt or support the product, candidate, or cause <span class="citation">(for a review, see <a href="references.html#ref-RefWorks:3940">Erdogan, 1999</a>; for an alternative approach, see <a href="references.html#ref-RefWorks:3941">McCracken, 1989</a>)</span>.</p>
<p>Imagine that we want to test if the celebrity who endorses a fund raiser in a fund-raising campaign makes a difference to people’s willingness to donate. We will be using the celebrities George Clooney and Angelina Jolie, and we will compare campaigns with one of them to a campaign without celebrity endorsement.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:clooneyjolie"></span>
<img src="figures/ClooneyJolie.png" alt="George Clooney and Angelina Jolie. Photo Clooney by Angela George [CC BY-SA 3.0](https://upload.wikimedia.org/wikipedia/commons/3/32/GeorgeClooneyHWoFJan12.jpg). Photo Jolie by Foreign and Commonwealth Office [CC BY 2.0](https://upload.wikimedia.org/wikipedia/commons/a/ad/Angelina_Jolie_2_June_2014_%28cropped%29.jpg), via Wikimedia Commons." width="50%" />
<p class="caption">
Figure 5.1: George Clooney and Angelina Jolie. Photo Clooney by Angela George <a href="https://upload.wikimedia.org/wikipedia/commons/3/32/GeorgeClooneyHWoFJan12.jpg">CC BY-SA 3.0</a>. Photo Jolie by Foreign and Commonwealth Office <a href="https://upload.wikimedia.org/wikipedia/commons/a/ad/Angelina_Jolie_2_June_2014_%28cropped%29.jpg">CC BY 2.0</a>, via Wikimedia Commons.
</p>
</div>
<p>Let us design an experiment to investigate the effects of celebrity endorsement. We sample a number of people (participants), whom we assign randomly to one of three groups. We show a campaign video with George Clooney to one group, a video with Angelina Jolie to another group, and the third group (<em>the control group</em>) sees a campaign video without celebrity endorsement. So we have three experimental conditions (Clooney, Jolie, no endorser) as our independent variable.</p>
<p>Our dependent variable is a numeric scale assessing the participant’s willingness to donate to the fund raiser on a scale from 1 (“absolutely certain that I will not donate”) to 10 (“absolutely certain that I will donate”). We will compare the average outcome scores among groups. If groups with Clooney or Jolie as endorser have systematically higher average willingness to donate than the group without celebrity endorsement, we conclude that celebrity endorsement has a positive effect.</p>
<p>In statistical terminology, we have a categorical independent (or predictor) variable and a numerical dependent variable. In experiments, we usually have a very limited set of treatment levels, so our independent variable is categorical. For nuanced results, we usually want to have a numeric dependent variable. Analysis of variance was developed for this kind of data <span class="citation">(<a href="references.html#ref-RefWorks:3955">R. A. Fisher, 1919</a>)</span>, so it is widely used in the context of experiments.</p>
<div id="anova-meandiffs" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Mean differences as effects<a href="5.1-different-means-for-three-or-more-groups.html#anova-meandiffs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-means">5.2</a> shows the willingness to donate scores for twelve participants in our experiment. Four participants saw Clooney, four saw Jolie, and four did not see a celebrity endorser in the video that they watched.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:anova-means"></span>
<iframe src="https://sharon-klinkenberg.shinyapps.io/anova-means/?showcase=0" width="540px" height="490px" data-external="1">
</iframe>
<p class="caption">
Figure 5.2: How do group means relate to effect size?
</p>
</div>
<p><A name="question7.1.1"></A></p>
<p><A name="question7.1.2"></A></p>
<p><A name="question7.1.3"></A></p>
<p>A group’s average score on the dependent variable represents the group’s score level. The group averages in Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-means">5.2</a> tell us for which celebrity the average willingness to donate is higher and for which situation it is lower.</p>
<p>Random assignment of test participants to experimental groups (e.g., which video is shown) creates groups that are in principle equal on all imaginable characteristics except the experimental treatment(s) administered by the researcher. Participants who see Clooney should have more or less the same average age, knowledge, and so on as participants who see Jolie or no celebrity. After all, each experimental group is just a random sample of participants.</p>
<p>If random assignment was done successfully, differences between group means can only be caused by the experimental treatment (we will discuss this in more detail in Chapter <a href="8-confounder.html#confounder">8</a>). Mean differences are said to represent the <em>effect</em> of experimental treatment in analysis of variance.</p>
<p>Analysis of variance was developed for the analysis of randomized experiments, where effects can be interpreted as causal effects. Note, however, that analysis of variance can also be applied to non-experimental data. Although mean differences are still called effects in the latter type of analysis, these do not have to be causal effects.</p>
<p>In analysis of variance, then, we are simply interested in differences between group means. The conclusion for a sample is easy: Which groups have higher average score on the dependent variable and for which are they lower? A means plot, such as Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-meansplot">5.3</a>, aids interpretation and helps communicating results to the reader. On average, participants who saw Clooney or Jolie have higher willingness to donate than participants who did not see a celebrity endorser.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:anova-meansplot"></span>
<img src="GentleIntro_files/figure-html/anova-meansplot-1.png" alt="A means plot showing that average willingness to donate is higher with a celebrity endorser than without a celebrity endorser. As a reading instruction, effects of endorsers are represented by arrows." width="70%" />
<p class="caption">
Figure 5.3: A means plot showing that average willingness to donate is higher with a celebrity endorser than without a celebrity endorser. As a reading instruction, effects of endorsers are represented by arrows.
</p>
</div>
<p>Effect size in an analysis of variance refers to the overall differences between group means. We use eta<sup>2</sup> as effect size, which gives the proportion of variance in the dependent variable (willingness to donate) explained or predicted by the group variable (experimental condition).</p>
<p>This proportion is informative and precise. If you want to classify the effect size in more general terms, you should take the square root of eta<sup>2</sup> to obtain <em>eta</em>. As a measure of association, eta can be interpreted with the following rules of thumb:</p>
<ul>
<li>0.1 (0 ≤ eta<sup>2</sup> &lt; .2) = small or weak effect,</li>
<li>0.3 (.2 ≤ eta<sup>2</sup> &lt; .4) = medium-sized or moderate effect,</li>
<li>0.5 (.4 ≤ eta<sup>2</sup>) = large or strong effect.</li>
</ul>
</div>
<div id="between-variance" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Between-groups variance and within-groups variance<a href="5.1-different-means-for-three-or-more-groups.html#between-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For a better understanding of eta<sup>2</sup> and the statistical test of an analysis of variance model, we have to compare the individual scores to the group averages and to the overall average. Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-between">5.4</a> adds overall average willingness to donate to the plot (horizontal black line) with participants’ scores and average experimental group scores (coloured horizontal lines).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:anova-between"></span>
<iframe src="https://sharon-klinkenberg.shinyapps.io/anova-between/?showcase=0" width="540px" height="490px" data-external="1">
</iframe>
<p class="caption">
Figure 5.4: Which part of score differences tells us about the differences between groups?
</p>
</div>
<p><A name="question7.1.4"></A></p>
<p><A name="question7.1.5"></A></p>
<p><A name="question7.1.6"></A></p>
<p><A name="question7.1.7"></A></p>
<p>Let us assume that we have measured willingness to donate for a sample of 12 participants in our study as depicted in Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-between">5.4</a>. Once we have our data, we first have a look at the percentage of variance that is explained, eta<sup>2</sup>. What does it mean if we say that a percentage of the variance is explained when we interpret eta<sup>2</sup>?</p>
<p>The variance that we want to explain consists of the differences between the scores of the participants on the dependent variable and the overall or grand mean of all outcome scores. Remember that a variance measures deviations from the mean. The dotted black arrows in Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-between">5.4</a> express the distances between outcome scores and the grand average. Squaring, summing, and averaging these distances over all observations gives us the total variance in outcome scores.</p>
<p>The goal of our experiment is to explain why some of our participants have a willingness to donate that is far above the grand mean (horizontal black line in Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-between">5.4</a>) while others score a lot lower. We hypothesized that participants are influenced by the endorser they have seen. If an endorser has a positive effect, the average willingness should be higher for participants confronted with this endorser.</p>
<p>If we know the group to which a participant belongs—which celebrity she saw endorsing the fundraising campaign—we can use the average outcome score for the group as the predicted outcome for each group member—her willingness to donate due to the endorser she saw. The predicted group scores are represented by the coloured horizontal lines for group means in Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-between">5.4</a>.</p>
<p>Now what part of the variance in outcome scores (dotted black arrows in Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-between">5.4</a>) is explained by the experimental treatment? If we use the experimental treatment as predictor of willingness to donate, we predict that a participant’s willingness equals her group average (horizontal coloured line) instead of the overall average (horizontal black line), which we use if we do not take into account the participant’s experimental treatment.</p>
<p>So the difference between the overall average and the group average is what we predict and explain by the experimental treatment. This difference is represented by the solid black arrows in Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-between">5.4</a>. The variance of the predicted scores is obtained if we average the squared sizes of the solid black arrows for all participants. This variance is called the <em>between-groups variance</em>.</p>
<p>Playing with the group means in Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-between">5.4</a>, you may have noticed that eta<sup>2</sup> is high if there are large differences between group means. In this situation we have high between-groups variance—large black arrows—so we can predict a lot of the variation in outcome scores between participants.</p>
<p>In contrast, small differences between group averages allow us to predict only a small part of the variation in outcome scores. If all group means are equal, we can predict none of the variation in outcome scores because the between-groups variance is zero. As we will see in Section <a href="5.1-different-means-for-three-or-more-groups.html#anova-model">5.1.3</a>, zero between-groups variance is central to the null hypothesis in analysis of variance.</p>
<p>The experimental treatment predicts that a participant’s willingness equals the average willingness of the participant’s group. It cannot predict or explain that a participant’s willingness score is slightly different from her group mean (the red double-sided arrows in Figure <a href="5.1-different-means-for-three-or-more-groups.html#fig:anova-between">5.4</a>). <em>Within-groups variance</em> in outcome scores is what we cannot predict with our experimental treatment; it is prediction error. In some SPSS output, it is therefore labeled as “Error”.</p>
</div>
<div id="anova-model" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> <em>F</em> test on the model<a href="5.1-different-means-for-three-or-more-groups.html#anova-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Average group scores tell us whether the experimental treatment has effects within the sample (Section <a href="5.1-different-means-for-three-or-more-groups.html#anova-meandiffs">5.1.1</a>). If the group who saw Angelina Jolie as endorser has higher average willingness to donate than the group who did not see an endorser, we conclude that Angelina Jolie makes a difference in the sample. But how about the population?</p>
<p>If we want to test whether the difference that we find in the sample also applies to the population, we use the null hypothesis that all average outcome scores are equal in the population from which the samples were drawn. In our example, the null hypothesis states that people in the population who would see George Clooney as endorser are on average just as willing to donate as people who would see Angelina Jolie or who would not see a celebrity endorser at all.</p>
<p>We use the variance in group means as the number that expresses the differences between group means. If all groups have the same average outcome score, the between-groups variance is zero. The larger the differences, the larger the between-groups variance (see Section <a href="5.1-different-means-for-three-or-more-groups.html#between-variance">5.1.2</a>).</p>
<p>We cannot just use the between-groups variance as the test statistic because we have to take into account chance differences between sample means. Even if we draw different samples from the same population, the sample means will be different because we draw samples at random. These sample mean differences are due to chance, they do not reflect true differences between groups in the population.</p>
<p>We have to correct for chance differences and this is done by taking the ratio of between-groups variance over within-groups variance. This ratio gives us the relative size of observed differences between group means over group mean differences that we expect by chance.</p>
<p>Our test statistic, then, is the ratio of two variances: between-groups variance and within-groups variance. The <em>F</em> distribution approximates the sampling distribution of the ratio of two variances, so we can use this probability distribution to test the significance of the group mean differences we observe in our sample.</p>
<p>Long story short: We test the null hypothesis that all groups have the same population means in an analysis of variance. But behind the scenes, we actually test between-groups variance against within-groups variance. That is why it is called analysis of variance.</p>
</div>
<div id="anova-assumpt" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Assumptions for the <em>F</em> test in analysis of variance<a href="5.1-different-means-for-three-or-more-groups.html#anova-assumpt" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are two important assumptions that we must make if we use the <em>F</em> distribution in analysis of variance: (1) independent samples and (2) homogeneous population variances.</p>
<div id="independent-samples-1" class="section level4 hasAnchor" number="5.1.4.1">
<h4><span class="header-section-number">5.1.4.1</span> Independent samples<a href="5.1-different-means-for-three-or-more-groups.html#independent-samples-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The first assumption is that the groups can be regarded as independent samples. As in an independent-samples <em>t</em> test, it must be possible <em>in principle</em> to draw a separate sample for each group in the analysis. Because this is a matter of principle instead of how we actually draw the sample, we have to argue that the assumption is reasonable. We cannot check the assumption against the data.</p>
<p>Here is an example of an argument that we can make. In an experiment, we usually draw one sample of participants and, as a next step, we assign participants randomly to one of the experimental conditions. We could have easily drawn a separate sample for each experimental group. For example, we first draw a participant for the first condition: seeing George Clooney endorsing the fundraising campaign. Next, we draw a participant for the second condition, e.g., Angelina Jolie. The two draws are independent: whomever we have drawn for the Clooney condition is irrelevant to whom we draw for the Jolie condition. Therefore, draws are independent and the samples can be regarded as independent.</p>
<p>Situations where samples cannot be regarded as independent are the same as in the case of dependent/paired-samples <em>t</em> tests (see Section <a href="2.3-theoretical-approx.html#dependentsamples">2.3.6</a>). For example, samples of first and second observations in a repeated measurement design should not be regarded as independent samples. Some analysis of variance models can handle repeated measurements but we do not discuss them here.</p>
</div>
<div id="homogeneous-population-variances" class="section level4 hasAnchor" number="5.1.4.2">
<h4><span class="header-section-number">5.1.4.2</span> Homogeneous population variances<a href="5.1-different-means-for-three-or-more-groups.html#homogeneous-population-variances" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The <em>F</em> test on the null hypothesis of no effect (the nil) in analysis of variance assumes that the groups are drawn from the same population. This implies that they have the same average score on the dependent variable in the population as well as the same variance of outcome scores. The null hypothesis tests the equality of population means but we must assume that the groups have equal dependent variable variances in the population.</p>
<p>We can use a statistical test to decide whether or not the population variances are equal (homogeneous). This is Levene’s <em>F</em> test, which is also used in combination with independent samples <em>t</em> tests. The test’s null hypothesis is that the population variances of the groups are equal. If we do <em>not</em> reject the null hypothesis, we decide that the assumption of equal population variances is plausible.</p>
<p>The assumption of equal population variances is less important if group samples are more or less of equal size (a balanced design, see Section <a href="5.3-different-means-for-two-factors.html#balanced">5.3.2</a>). We use a rule of thumb that groups are of equal size if the size of the largest group is less than 10% (of the largest group) larger than the size of the smallest group. If this is the case, we do not care about the assumption of homogeneous population variances.</p>
</div>
</div>
<div id="which-groups-have-different-average-scores" class="section level3 hasAnchor" number="5.1.5">
<h3><span class="header-section-number">5.1.5</span> Which groups have different average scores?<a href="5.1-different-means-for-three-or-more-groups.html#which-groups-have-different-average-scores" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Analysis of variance tests the null hypothesis of equal population means but it does not yield confidence intervals for group means. It does not always tell us which groups score significantly higher or lower.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:anova-posthoc"></span>
<iframe src="https://sharon-klinkenberg.shinyapps.io/anova-posthoc/?showcase=0" width="525px" height="485px" data-external="1">
</iframe>
<p class="caption">
Figure 5.5: Which groups have different average outcome scores in the population? The <em>p</em> values belong to independent-samples <em>t</em> tests on the means of two groups.
</p>
</div>
<p><A name="question7.1.8"></A></p>
<p><A name="question7.1.9"></A></p>
<p><A name="question7.1.10"></A></p>
<p>If the <em>F</em> test is statistically significant, we reject the null hypothesis that all groups have the same population mean on the dependent variable. In our current example, we reject the null hypothesis that average willingness to donate is equal for people who saw George Clooney, Angelina Jolie, or no endorser for the fund raiser. In other words, we <em>reject</em> the null hypothesis that the endorser does <em>not</em> matter to willingness to donate.</p>
<div id="pairwise-comparisons-as-post-hoc-tests" class="section level4 hasAnchor" number="5.1.5.1">
<h4><span class="header-section-number">5.1.5.1</span> Pairwise comparisons as post-hoc tests<a href="5.1-different-means-for-three-or-more-groups.html#pairwise-comparisons-as-post-hoc-tests" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>With a statistically significant <em>F</em> test for the analysis of variance model, several questions remain to be answered. Does an endorser increase or decrease the willingness to donate? Are both endorsers equally effective? The <em>F</em> test does not provide answers to these questions. We have to compare groups one by one to see which condition (endorser) is associated with a higher level of willingness to donate.</p>
<p>In a pairwise comparison, we have two groups, for instance, participants confronted with George Clooney and participants who did not see a celebrity endorse the fund raiser. We want to compare the two groups on a numeric dependent variable, namely their willingness to donate. An independent-samples <em>t</em> test is appropriate here.</p>
<p>With three groups, we can make three pairs: Clooney versus Jolie, Clooney versus nobody, and Jolie versus nobody. We have to execute three <em>t</em> tests on the same data. We already know that there are most likely differences in average scores, so the <em>t</em> tests are executed after the fact, in Latin <em>post hoc</em>. Hence the name <em>post-hoc tests</em>.</p>
<p>Applying more than one test to the same data increases the probability of finding at least one statistically significant difference even if there are no differences at all in the population. Section <a href="4.7-critical-discussion.html#cap-chance">4.7.3</a> discussed this phenomenon as capitalization on chance and it offered a way to correct for this problem, namely Bonferroni correction. We ought to apply this correction to the independent-samples <em>t</em> tests that we execute if the analysis of variance <em>F</em> test is statistically significant.</p>
<p>The Bonferroni correction divides the significance level by the number of tests that we do. In our example, we do three <em>t</em> tests on pairs of groups, so we divide the significance level of five per cent by three. The resulting significance level for each <em>t</em> test is .0167. If a <em>t</em> test’s <em>p</em> value is below .0167, we reject the null hypothesis, but we do not reject it otherwise.</p>
</div>
<div id="two-steps-in-analysis-of-variance" class="section level4 hasAnchor" number="5.1.5.2">
<h4><span class="header-section-number">5.1.5.2</span> Two steps in analysis of variance<a href="5.1-different-means-for-three-or-more-groups.html#two-steps-in-analysis-of-variance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Analysis of variance, then, consists of two steps. In the first step, we test the general null hypothesis that all groups have equal average scores on the dependent variable in the population. If we cannot reject this null hypothesis, we have too little evidence to conclude that there are differences between the groups. Our analysis of variance stops here, although it is recommended to report the confidence intervals of the group means to inform the reader. Perhaps our sample was just too small to reject the null hypothesis.</p>
<p>If the <em>F</em> test is statistically significant, we proceed to the second step. Here, we apply independent-samples <em>t</em> tests with Bonferroni correction to each pair of groups to see which groups have significantly different means. In our example, we would compare the Clooney and Jolie groups to the group without celebrity endorser to see if celebrity endorsement increases willingness to donate to the fund raiser, and, if so, how much. In addition, we would compare the Clooney and Jolie groups to see if one celebrity is more effective than the other.</p>
</div>
<div id="contradictory-results" class="section level4 hasAnchor" number="5.1.5.3">
<h4><span class="header-section-number">5.1.5.3</span> Contradictory results<a href="5.1-different-means-for-three-or-more-groups.html#contradictory-results" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>It may happen that the <em>F</em> test on the model is statistically significant but none of the post-hoc tests is statistically significant. This mainly happens when the <em>p</em> value of the <em>F</em> test is near .05. Perhaps the correction for capitalization on chance is too strong; this is known to be the case with the Bonferroni correction. Alternatively, the sample can be too small for the post-hoc test. Note that we have fewer observations in a post-hoc test than in the <em>F</em> test because we only look at two of the groups.</p>
<p>This situation illustrates the limitations of null hypothesis significance tests (Chapter <a href="4.7-critical-discussion.html#critical-discussion">4.7</a>). Remember that the 5 per cent significance level remains an arbitrary boundary and statistical significance depends a lot on sample size. So do not panic if the <em>F</em> and <em>t</em> tests have contradictory results.</p>
<p>A statistically significant <em>F</em> test tells us that we may be quite confident that at least two group means are different in the population. If none of the post-hoc <em>t</em> tests is statistically significant, we should note that it is difficult to pinpoint the differences. Nevertheless, we should report the sample means of the groups (and their standard deviations) as well as the confidence intervals of their differences as reported in the post-hoc test. The two groups that have most different sample means are most likely to have different population means.</p>
<p><A name="answer7.1.1"></A></p>
<p><A name="answer7.1.2"></A></p>
<p><A name="answer7.1.3"></A></p>
<p><A name="answer7.1.4"></A></p>
<p><A name="answer7.1.5"></A></p>
<p><A name="answer7.1.6"></A></p>
<p><A name="answer7.1.7"></A></p>
<p><A name="answer7.1.8"></A></p>
<p><A name="answer7.1.9"></A></p>
<p><A name="answer7.1.10"></A></p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="5-anova.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="5.2-onewaySPSS.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

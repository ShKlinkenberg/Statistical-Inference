# Moderation with Analysis of Variance (ANOVA) {#anova}
> Key concepts: between groups variance, within groups variance, homogeneous population variances, capitalization on chance, post-hoc tests, main effects, interaction effects, moderation, predictor, moderator,

{Summary TBD}

### Test your intuition or knowledge {-}

```{r}
# TBD: Manipulate group means in a 3x2 design with means plots: create main and interaction effects.
```

## Different Score Levels for Three or More Groups

: example: the celebrity (George Clooney versus Angelina Jolie versus no endorser) endorsing a fundraising campaign (treatment) makes a difference to people's willingness to donate (outcome) {later on moderated by sex of the subject}

: experiment as design: comparing groups on a numeric result (outcome) ; average group scores as effects ; differences between groups created by the researcher (experimental treatment, factor with levels) - usually a very limited set of treatment levels, so categorical independent/predictor variable 

: note: analysis technique of this chapter applies also to non-experimental situations in which groups (categorical variable) are compared with respect to the elvel of their scores (numeric outcome variable)

### Mean differences as effects
```{r anova-means, fig.cap="How do group means relate to effect size?"}
# Goal: Illustrate that differences between group means represent effects (effect size given by eta^2).
# Generate 4 random observations from a normally distributed population with mean 6.4, sd = 1 (Clooney), 4 observations from a population N(m = 6.8, sd = 1) (Jolie), and 4 observations from N(m = 3.3, sd = 1) (no endorser). Use colour for the treatment factor (3 levels). Represent observations in a dotplot, each with a separate value on the x axis, clustered by factor level (experimental condition). Display group means as horizontal line segments (coloured by factor level). Add vertical double-sided arcs between each pair of group means to illustrate group differences. Display eta^2 for the data. Allow user to change the group means and update the plot, mean (difference) lines, and eta^2.
```

1. In the sample of (12) subjects displayed in Figure \@ref(fig:anova-means), what do the double-sided vertical arcs represent?

2. How do the double-sided vertical arcs relate to effect size (eta^2^)? Explain the relation in your own words and change group means to verify your expectations.

: mean differences as effects (e.g., of experimental treatment) ; mean plots for interpretation ; concusion for sample is easy: which group has a higher or lower average score on the outcome variable?

: eta^2^ as effect size ; interpret as proportion of variance in the outcome (willingness to donate) explained/predicted by group variable (experimental condition) ; {explanation in terms of between groups variance in next section}

Rules of thumb for the interpretation of eta^2^: 

* 0,01 is a small or weak effect; 1% variance explained matches a correlation r = 0,10 because R^2^ in simple regression analysis equals r squared,

*	0,09 medium-sized or moderate effect, matches r = 0,30,
*	0,25 large or strong effect; matches r = 0,50.

### Between groups variance
```{r anova-between}
# Goal: Illustrate that between groups variance represents differences between group means and the grand mean. And that it is a (smaller or larger) proportion of total variance.
# App anova-means: Generate 4 random observations from a normally distributed population with mean 6.4, sd = 1 (Clooney), 4 observations from a population N(m = 6.8, sd = 1) (Jolie), and 4 observations from N(m = 3.3, sd = 1) (no endorser). Use colour for the treatment factor (3 levels). Represent observations in a dotplot, each with a separate value on the x axis, clustered by factor level (experimental condition). Display group means as horizontal line segments (coloured by factor level). Display eta^2 for the data. Allow user to change the group means and update the plot, mean (difference) lines, and eta^2.
# Extension/replacement: Add horizontal line for grand mean, vertical red solid double-sided arcs between each observation and the grand mean (total variance), vertical black solid double-sided arcs for each observation between its group mean and the grand mean (between variance), and vertical black dotted double-sided arcs for each observation between the dot and its group mean (within variance). 
```

1. In Figure \@ref(fig:anova-between), what do the solid red double-sided arcs represent?

2. What do the solid black double-sided arcs represent?

3. Which double-sided arcs relate to effect size eta^2^? Change group means to verify your expectation.

4. What do the dotted black double-sided arcs in Figure \@ref(fig:anova-between) represent?

: what does it mean that a percentage of the variance is explained, as we say when we interpret eta^2^? ; the variance that we want to explain are the differences in the scores of the subjects on the outcome variable ; why do some subjects have a high willingness to donate and other subjects a lower willingness? ; the red double-sided arcs Figure \@ref(fig:anova-between) express the variance in outcome scores, which is their (squared) distance from the grand mean

: we want to explain the variation in willingness from the experimental treatment of the subjects: Which endorser are the subjects exposed to? ; if an endorser is more effective, the overall level of willingness should be higher ; in other words, the average willingness should be higher for subjects confronted with this endorser 

: group average willingness is what we can predict from the experimental treatment ; if we know the group to which a subject belongs---which celebrity she saw endorsing the fundraising campaign---we can use the average outcome score for the group as the predicted outcome for each group member---her willingness to donate ; the predicted group scores are represented by the horizontal lines for group means in Figure \@ref(fig:anova-between)

: now what part of the variance in outcome scores (red double-sided arcs in Figure \@ref(fig:anova-between)) is explained by the predicted values, that is, group means? ; this is the variance of the predicted scores, which is the (squared) deviation between the group mean and the grand mean for all observations ; this is called the between groups variance and it is represented by the solid black double-sided arcs in Figure \@ref(fig:anova-between)

: playing with the group means in Figure \@ref(fig:anova-between), you may have noticed that eta^2^ is high if there are large differences between group means ; in this situation we have high between groups variation, so we can predict a lot of the variation in outcome scores beween subjects 

: in contrast, small differences between group averages allow us to predict only a small part of the variation in outcome scores ; if all group means are equal, we can predict none of the variation in outcome scores because the between groups variance is zero ; as we will see in Section \@ref(anova-model), zero between groups variance is central to the null hypothesis in analysis of variance

### Within groups variance
```{r}
# Goal: Sensitize students to the fact that larger population variance creates larger random variance of sample means.
# 3 populations (of willingness to donate scores; arrange vertically, so means can easily be compared) with equal means and variances ; add button to draw a random sample from all three populations (N = 10 per sample) and display as (3 vertically arranged) dotplots ; display the mean for each sample (line in dotplot) ; calculate and display (add to scatterplot of population variance (X) by random between groups variance (Y)?) the between groups variance of the three sample means ; allow user to change the population variance (population variance) to see how it relates to random between groups variance
```

1. @

: if we draw samples from the same population or from populations with the same means, the sample means can still be different because we draw samples at random ; these sample mean differences are due to chance, they do not reflect real differences between the populations

: random samples from the same population can only have different sample means if there is variation in the population scores ; after all, if all people exposed to George Clooney as endorser would have exactly the same willingness to donate, every random sample drawn from these people would contain people with exactly the same willingness to donate, so the average willingness would also be exactly the same for all samples

: the variation in scores within a population, such as all people who owuld be exposed to George Clooney as endorser, is called within group variance ; within groups variance gives rise to chance differences between means of sample drawn from the same or identical population

: the amount of variation in population scores is important ; chance differences between sample means are more likely to be larger if the within group variation is larger ; you are more likely to draw some observations far away from the population mean if score variation is larger in the population ; observations far from the mean influence the sample mean strongly, so the means of samples will fluctuate more

: within group variance in outcome scores is what we cannot predict with our grouping variable ; after all, each member of the same group has the same predicted score, namely the group average ; within groups varaince within a sample is represented by the dotted double-sided arcs in Figure \@ref(fig:anova-between) ; we cannot predict this type of variance but 

### F test on the model {#anova-model}
: average group scores tell us whether the experimental treatment has effects within the sample(s) ; if the group who saw Angelina Jolie as endorser has higher average willingness to donate than the group who did not see an endorser, we conclude that Angelina Jolie makes a difference in the sample ; but how about the population?

: if we want to test whether the difference also applies to the population, we use the substantive null hypothesis that all average outcome scores are equal in the populations form which the samples were drawn ; in our example, the null hypothesis expects that people who would see George Clooney as endorser, are not more or less willing to donate than people who would see Angelina Jolie or not see an endorser at all

: a statistical test requires a single number that expresses how close the sample result is to the hypothesis ; how can we express the equality of three or more population means in one number?

: equality of two means in an independent-samples t test: take difference as one number to test ; however, subtraction does not work for 3+ groups ; equality of three or more population means as one number: no variation (variance) in group means ; in other words, between groups variance is zero in the population ; hence, name analysis of variance (ANOVA) 

: complication: we have seen that within group variance results in chance differences between sample means ; we cannot expect that between groups variance is zero in our sample due to chance differences between group means ; we have to correct for chance differences and this is done by taking the ratio of between groups variance over within groups variance: the relative size of observed differences between group means against group mean differences that are expected by chance

: our test statistic, then, is the ratio of two variances: between groups and within group variance ; the F distribution approximates the sampling distribution of the ratio of two variances, so we can use this probability distribution to test the significance of the group mean differences we observe in our sample

: remember that we used the F distribution before for testing a ratio of two variances, namely, in Levene's F test for the null hypothesis that two groups have the same population variance (Section \@ref(Levene-2groups)) 

: long story short: we test the substantive null hypothesis that all groups have the same population means in an analysis of variance ; but behind the screens, we actually test between groups variance against within group variance ; that is why it is called analysis of variance

### Statistical significance of F values
: the F statistic for a sample increases with larger differences between group means (what we can predict) and it decreases with larger differences of scores within groups (what we cannot predict and may be caused by chance) ; larger F values, then, indicate that we can predict a larger part of the variation in outcome scores, e.g., willigness to donate

: higher F values indicate that the observed differences between group means in the sample are less likely to occur purely based on chance, that is, if the population means are equal for all groups

: so we are more confident that the null hypothesis of equal population means must be rejected if the value of the F test is higher

### Assumptions for the F test in analysis of variance {#anova-assumpt}
: there are two important assumptions that we must make if we use the F distribution in analysis of variance: Independent samples and homogeneous population variances

#### Independent samples
: the first assumption is that the groups can be regarded as independent samples ; just like an independent-samples t test, it must be possible _in principle_ to draw a separate sample for each group in the analysis ; because it is a matter of principle instead of how we actually have drawn the sample(s), we have to argue that the assumption is reasonable ; we cannot check the assumption against the data 

: this is an example of an argument ; in an experiment, we usually draw one sample of subjects ; we assign subjects randomly to one of the experimental conditions ; this can easily be done separately for each experimental group ; for example, we first draw a subject for the first condition, e.g., seeing George Clooney endorsing the fundraising campaign ; next, we draw a subject for the second condition, e.g., Angelina Jolie ; the two draws are independent: whomever we have drawn for the Clooney condition is irrelevant to whom we draw for the Jolie condition ; the draws can be independent, so the samples can be regarded as independent

: the situation where samples cannot be regarded as independent are the same as in the case of t tests (see Section \@ref(dependentsamples)); for example, the samples of first and second observations in a repeated measurement design should not be regarded as independent samples

#### Homogeneous population variances
: the F test in analysis of variance assumes that the groups are drawn from the same population ; this implies that they have the same average score on the outcome variable in the population but also the same variance of outcome scores ; the null hypothesis tests the equality of population means but we must assume that the groups have equal outcome varable variances in the population

: we can use a statistical test to decide whether or not the population variances are equal (homogeneous) ; this is Levene's F test, which we also used for this purpose in independent samples t tests (Section \@ref(comp-means)) ; the test's null hypothesis is that the population variances of the groups are equal ; if we do _not_ reject the null hypothesis, we decide that the assumption of equal population variances is plausible

: the assumption of equal population variances is less important if the group samples are more or less of equal size ; we use a rule of thumb that groups are of equal size if the size of the largest group is less than 10% larger than the size of the smallest group in the analysis of variance ; if this is the case, we do not care about the assumption of homogeneous population variances 

### Which groups have different average scores?
: if the F test is statistically significant, we reject the null hypothesis that all groups have the same population mean on the outcome variable ; in our current example, we reject the null hypothesis that average willingness to donate is equal for people who saw George Clooney, Angelina Jolie, or no endorser for the fund raiser ; in other words, we reject the null hypothesis that the endorser does _not_ matter to willingness to donate

: but does an endorser increase or decrease the willingness to donate? ; are both endorsers equally effective? ; the F test does not provide answers to these questions ; we have to compare groups pair by pair to see which condition (endorser) is associated with a higher level of willingness to donate

: we can use independent-samples t test for the pairwise comparisons ; after all, we have two groups, for example, subjects confronted with George Clooney and subject who did not see a celebrity endorse the fund raiser, that we want to compare on a numeric outcome, namely their willingness to donate

: with three groups, we can make three pairs: Clooney-Jolie, Clooney-nobody, and Jolie-nobody ; so we have to execute three t tests on the same data ; we already know that there probably are differences in average scores, so the t tests are executed "after the fact," in latin _post hoc_

: applying more than one test to the same data increases the probability of finding at least one statistically significant difference even if there are no differences at all in the population ; Section \@ref(cap-chance) discussed this as capitalization on chance and it offered a way to correct for this problem, namely the Bonferroni correction

### Contradictory results
: it may happen that the F test on the model is statistically significant but none of the post hoc tests ; this usually happens when the F test is just significant ; perhaps the correction for capitalization is too strong ; this is known to be the case with the Bonferroni correction ; alternatively, the sample is too small for the post hoc test ; note that we have fewer observations in a post hoc test than in the F test because we only look at two of the groups

: this situation illustrates the limitations of null hypothesis significance tests (Chapter \@ref(crit-discus)) ; remember that the 5% significance level remains an arbitrary boundary 

: a statistically significant F test tells us that we may be quite confident that at least two group means are different in the population ; if none of the post hoc t tests is statistically significant, we should note that it is difficult to pinpoint the differences ; nevertheless, we should report the sample means of the groups (and their standard deviations) ; the two groups that have the most different sample means are most likely to have different population means

### SPSS and analysis of variance
{TBD: instruction & interpretation videos, use Fam's videos?}
: refresh one-way analysis of variance (in SPSS)
{corrected confidence intervals for post-hc tests in SPSS}

### SPSS exercises

{TBD}

## Different Score Levels for Two Factors

```{r}
# Goal: Illustrate that different main effects merely use means of different groupings.
# Similar to app anova-means.
# Generate 6 sets of 2 random observations from a normally distributed population with mean runif(3, 7) and sd = 1. Assign the groups to the experimental treatment factor (endorser, 3 levels) and sex factor (2 levels). Represent observations in a dotplot with treatment as dot colour and sex as dot shape, each observation with a separate value on the x axis, ordered by factor levels. Display grand mean as a horizontal line. Allow user to select (display) group means on one of the two factors. On selection, (old group means vanish and) the group means are added as horizontal lines (coloured for the 3 levels factor and different line styles for 2 levels factor) with within and between group variation indicated by double-sided arcs between dot and group mean (within) and between group mean and grand mean (between). Add button to draw new samples
```

1. How does an analysis of variance test the effect of endorser on willingness to donate with the data displayed in Figure \@ref(fig:)? Select the endorser factor in the list box to check your answer.

2. Which effect on willingness to donate is probably stronger: the effect of endorser or of sex? Motivate your answer. Compare a plot with the endorser factor selected to a plot with the sex factor selected.

3. If you want to practice more, draw new samples.

In the preceding section, we have looked at  the effect of a single facor, namely, the endorser to whom subjects are exposed, on willingness to donate. Thus, we take into account two variables---one predictor and one outcome variable---so this is an example of a bivariate analysis.

Usually, however, we expect an outcome to depend on more than one variable. Willingness to donate most likely not just depends on the celebrity endorsing a fundraising campaign. It is easy to think of more factors, such as a person's available budget, her personal level of altruism, and so on. 

It is straightforward to include more factors in an analysis of variance. These can be additional experimental treatments in the context of an experiment as well as subject characteristics that are not manipulated by the researcher. For example, we may hypothesize that females are generally more charitable than males.

### Two-way analysis of variance
If we use two factors, the analysis is called two-way analysis of variance. With one factor, it is called one-way analysis of variance, and with three factors ... well, you probably already guessed the name. 

A two-way analysis of variance with the first factor containing three levels, for example, exposure to three different endorsers, and the second containing two levels, for example, female versus male, is called a 3x2 (say: three by two) factorial design.

### Balanced design
In analysis of variance with two or more factors, it is quite nice if the factors are Statistcally indepent from one another. In other words, it is nice if the scores on one factor are not associated with scores on another factor. This is called a balanced design. 

In an experiment, we can ensure that factors are independent if we have the same number of subjects in each combination of levels on all factors. In other words, if we have the same number of observations in each subgroup, where a subgroup is a combination of a group on one factor and a group on another factor. 

```{r anova-balanced, echo=FALSE}
# Table for a balanced 3x2 factorial design.
# Create data.
df <- data.frame(Female = rep(5, 3), Male = rep(5, 3))
row.names(df) <- c("Clooney", "Jolie", "No endorser")
# Display table.
knitr::kable(df, caption = "Number of observations per subgroup in a balanced 3x2 factorial design.")
# Cleanup.
rm(df)
```

Table \@ref(tab:anova-balanced) shows an example of a balanced 3x2 factorial design. Each subgroup (cell) contains five subjects (observations). If you remember the principles of statistical association and independence in crosstabulations (Section \@ref(score-combi)), you know that equal distributions of frequencies across columns or across rows indicate statistical independence. In the example, the distributions are the same across columns (and rows), so the factors are statistically independent.

A balanced design is nice but not necessary. Unbalanced designs can be analyzed but estimation is more complicated (problem for the computer, not for us) and the assumption of equal population variances for all groups is more important (problem for us, not for the computer).

### Main effects in two-way analysis of variance
A two-way analysis of variance tests the effects of both factors on the outcome variable in one go. It tests the null hypothesis that subjects exposed to Clooney have the same average willingness to donate in the population as subjects exposed to Jolie or not exposed to an endorser. At the same time is it tests the null hypothesis that females and males have the same willingness to donate in the population.

The tested effects are main effects, that is, an overall or average difference between the mean scores of the groups on the outcome variable. The main effect of the endorser factor shows the mean differences for endorser groups if we do not distinguish between females and males. Likewise, the main effect for sex shows the average difference in willingness to donate between females and males without taking into account to which endorser they were exposed.

We could have used two separate one-way analyses of variance to test the same effects. Moreover, we could have tested the difference between females and males with an independent-samples t test. The results would have been the same (exactly the same because the design is balanced.) But there is an important advantage to using a two-way analysis of variance, to which we turn in the next section.

## Score Level Differences that Depend on Context

{TBD: the concept of moderation ; picture (sketch as video) as icon for moderation}

In the preceding section, we have analyzed the effects both of endorser and sex on willingness to donate to a fund raiser. The two main effects isolate the influence of endorser on willingness from the effect of sex and the other way around. These effect assume that endorser and sex have an effect on their own. Some kind of general effect.

We should, however, wonder whether the effects are always the same. Even if there is a general effect of endorser on willingness to donate, is this effect the same for females and males? Note that one endorser is a male celebrity who is reputed to be quite attractive to women. The other endorser is a female celebrity with a similar reputation among men. In this situation, shouldn't we expect that one endorser is more effective among female subjects and the other among male subjects?

If the effect of a factor is different for different groups on another factor, the first factor's effect is _moderated_ by the second factor. The phenomenon that effects are moderated is called _moderation_. 

### Types of moderation

Moderation happens a lot in communication science for the simple reason that the effects of messages are stronger for people who are more susceptible to the message. Children tend to be more impressionable than adults. People who have 

Moderation means different effects for different groups or in different contexts. 
: are effects (as mean differences) always the same? ; a variety of contextual differences: effect in one group, not the other, effect stronger in one group than the other, effect in one group opposite of effect in other group 
 
; mean plots for interpretation 

: overall or main effects versus context-specific or interaction effects 

; conceptual diagram ; In addition, the factors can have a combined effect. 


; separate versus joint statistical analysis: two one-way analyses of variance versus one two-way analysis of variance: statistical inference (sampling distribution) for the difference between mean differences 

This brings us to the assumptions for a two-way analysis of variance. They are the same as for a one-way analysis of variance (Section \@ref(anova-assumpt)) except that equal group sizes now apply to the subgroups formed by the combination of the two factors.

### SPSS and two-way analysis of variance

{TBD}

### SPSS exercises

{TBD}

## Take-Home Points  

* In an analysis of variance, we test the substantive null hypothesis that all groups or subgroups have the same population means. Behind the screens, we actually test between groups variance against within group variance.

* main effect

* interaction effect

* moderation

* effect size

* assumptions

* {TBD}
